# ==============================================================================
# REdI | CritLit Environment Configuration Template
# ==============================================================================
# This file serves as a template for the .env file required to run the
# Systematic Literature Review (SLR) application stack with Docker Compose.
#
# SETUP INSTRUCTIONS:
# 1. Copy this file to .env: `cp .env.example .env`
# 2. Replace all placeholder values with your actual credentials
# 3. Never commit the .env file to version control (already in .gitignore)
# ==============================================================================

# ------------------------------------------------------------------------------
# Database Configuration
# ------------------------------------------------------------------------------

# PostgreSQL password for the database user 'slr_user'
# SECURITY: Use a strong password (minimum 16 characters, mix of upper/lower/numbers/symbols)
POSTGRES_PASSWORD=your_secure_password_here

# ------------------------------------------------------------------------------
# n8n Workflow Automation
# ------------------------------------------------------------------------------

# n8n basic authentication username
# This is the username you'll use to log into the n8n web interface
N8N_USER=admin

# n8n basic authentication password
# SECURITY: Use a strong password different from your database password
N8N_PASSWORD=your_n8n_password

# n8n encryption key for securing credentials stored in the database
# GENERATE: Use `openssl rand -base64 32` to generate a secure key
# IMPORTANT: Do not change this after initial setup or you'll lose access to stored credentials
# WARNING: If you see "Mismatching encryption keys" error, see docs/QUICKSTART.md troubleshooting
N8N_ENCRYPTION_KEY=your_encryption_key_base64

# n8n API Key for MCP server (generate from n8n Settings > API)
# PURPOSE: Allows the n8n-mcp service to interact with n8n workflows via Model Context Protocol
# OBTAIN: Log into n8n at http://localhost:7361, go to Settings > API, and generate an API key
N8N_API_KEY=

# ------------------------------------------------------------------------------
# External API Keys - Research Data Sources
# ------------------------------------------------------------------------------

# PubMed/NCBI API Key
# OBTAIN: Register at https://www.ncbi.nlm.nih.gov/account/
# PURPOSE: Required for enhanced PubMed search rate limits (10 requests/sec vs 3/sec without key)
PUBMED_API_KEY=your_ncbi_api_key

# Contact email for API requests
# PURPOSE: Many APIs (especially PubMed) require a contact email for rate limit compliance
# RECOMMENDATION: Use your institutional or professional email address
CONTACT_EMAIL=researcher@example.com

# ------------------------------------------------------------------------------
# External API Keys - AI/LLM Services
# ------------------------------------------------------------------------------

# Anthropic Claude API Key
# OBTAIN: Register at https://console.anthropic.com/
# PURPOSE: Powers AI-assisted screening, data extraction, and quality assessment
ANTHROPIC_API_KEY=your_claude_api_key

# OpenAI API Key
# OBTAIN: Register at https://platform.openai.com/
# PURPOSE: Alternative LLM provider for AI-assisted tasks
OPENAI_API_KEY=your_openai_key

# ------------------------------------------------------------------------------
# Institutional Access
# ------------------------------------------------------------------------------

# Ex Libris Primo API Key
# OBTAIN: Contact your institutional library or IT department
# PURPOSE: Enables full-text access via institutional subscriptions
# NOTE: Optional - only required if using Primo for institutional article access
PRIMO_API_KEY=your_institutional_key

# ------------------------------------------------------------------------------
# Ollama Local LLM Configuration
# ------------------------------------------------------------------------------

# Ollama base URL (default: http://ollama:11434)
OLLAMA_BASE_URL=http://ollama:11434

# Ollama model to use for screening (will be pulled on first use)
# Options: llama3.1:8b, llama3.1:70b
OLLAMA_SCREENING_MODEL=llama3.1:8b

# ------------------------------------------------------------------------------
# I-Librarian PDF Management
# ------------------------------------------------------------------------------

# Maximum upload file size for I-Librarian
ILIBRARIAN_UPLOAD_MAX_SIZE=100M

# ------------------------------------------------------------------------------
# Application Settings
# ------------------------------------------------------------------------------

# Batch size for screening operations (documents per batch)
SCREENING_BATCH_SIZE=50

# Confidence threshold for automatic inclusion decisions (0.0 to 1.0)
# Decisions below this threshold require human review
SCREENING_CONFIDENCE_THRESHOLD=0.85

# Maximum retries for external API calls
MAX_API_RETRIES=3

# Retry delay in seconds for external API calls
API_RETRY_DELAY=5
